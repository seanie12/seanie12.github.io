---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am a PhD student at <a href="https://www.mlai-kaist.com/" style="color: #7289da; text-decoration: none;">Machine Learning and Artificial Intelligence (MLAI)</a> lab in KAIST, working on meta-learning and machine learning. I am fortunate to be advised by Professor <a href="http://www.sungjuhwang.com/" style="color: #7289da; text-decoration: none;">Sung Ju Hwang</a> and <a href="https://juho-lee.github.io/" style="color: #7289da; text-decoration: none;">Juho Lee</a>. I also closely collaborate with <a href="https://ml.comp.nus.edu.sg/kawaguchi" style="color: #7289da; text-decoration: none;">Kenji Kawaguchi</a>. My research is graciously supported by the <a href="https://machinelearning.apple.com/updates/apple-scholars-aiml-2023" style="color: #7289da; text-decoration: none;">Apple Scholars in AI Fellowship</a>. Here is my <a href="https://seanie12.github.io/assets/cv.pdf" class="link-in-list" style="color: #7289da; text-decoration: none;"> cv</a>.



# üî• News
- *2023.09*: &nbsp;üéâüéâ I got an internship offer from <a href="https://mila.quebec/en/" style="color: #7289da; text-decoration: none;" >Mila</a>, supervised by <a href="https://yoshuabengio.org/" style="color: #7289da; text-decoration: none;">Yoshua Bengio</a>.
- *2023.09*: &nbsp;üéâüéâ One paper accepted to NeurIPS 2023.
- *2023.04*: &nbsp;üéâüéâ Two papers accepted to ICML 2023.
- *2023.03*: &nbsp;üéâüéâ Selected as a 2023 recipient of the <a href="https://machinelearning.apple.com/updates/apple-scholars-aiml-2023" style="color: #7289da; text-decoration: none;">Apple Scholars in AI ML PhD fellowship</a>.
- *2023.01*: &nbsp;üéâüéâ Two papers accepted to ICLR 2023.
- *2022.10*: &nbsp;‚úàÔ∏è‚úàÔ∏è **Google Travel Grant** for NeurIPS 2022 from Google.
- *2022.09*: &nbsp;üéâüéâ Two papers accepted to NeurIPS 2022. 
- *2022.05*: &nbsp;üéâüéâ One paper accepted to ICML 2022. 
<!-- - *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  -->

# üìù Publications 


- <font size="4">Self-Supervised Dataset Distillation for Transfer Learning</font>
[[paper]](https://arxiv.org/abs/2310.06511) \\
Dong Bok Lee\*, **Seanie Lee\***, Joonho Ko, Kenji Kawaguchi, Juho Lee and Sung Ju Hwang (\*: equal contribution) \\
<span style="color:purple">**Arxiv**</span> 2023

- <font size="4">Drug Discovery with Dynamic Goal-aware Fragments</font>
[[paper]](https://arxiv.org/abs/2310.00841) \\
Seul Lee, **Seanie Lee** and Sung Ju Hwang \\
<span style="color:purple">**Arxiv**</span> 2023

- <font size="4">Knowledge-Augmented Reasoning Distillation for Small Language Models in Knowledge-Intensive Tasks</font>
[[paper]](https://arxiv.org/abs/2305.18395) \\
Minki Kang, **Seanie Lee**, Jinheon Baek, Kenji Kawaguchi and Sung Ju Hwang \\
<span style="color:purple">**NeurIPS**</span> 2023


- <font size="4">DiffusionNAG: Task-guided Neural Architecture Generation with Diffusion Models</font>
[[paper]](https://arxiv.org/abs/2305.16943) \\
Sohyun Ahn\*  Hayeon Lee\*, Jaehyeong Jo, **Seanie Lee** and Sung Ju Hwang (\*: equal contribution) \\
<span style="color:purple">**Arxiv**</span> 2023


- <font size="4">Scalable Set Encoding with Universal Mini-Batch Consistency and Unbiased Full Set Gradient Approximation</font>
[[paper]](https://arxiv.org/abs/2208.12401) \\
Jeffrey Willette\*  **Seanie Lee**\*, Bruno Andreis, Kenji Kawaguchi, Juho Lee and Sung Ju Hwang (\*: equal contribution) \\
<span style="color:purple">**ICML**</span> 2023


- <font size="4">Margin-based Neural Network Watermarking</font>
[[paper]](https://proceedings.mlr.press/v202/kim23o.html) \\
Byungjoo Kim, Suyoung Lee,  **Seanie Lee**, Sooel Son and Sung Ju Hwang  \\
<span style="color:purple">**ICML**</span> 2023

- <font size="4">Self-Distillation for Further Pre-training of Transformers</font>
[[paper]](https://openreview.net/forum?id=kj6oK_Hj40) \\
 **Seanie Lee**, Minki Kang,  Juho Lee, Sung Ju Hwang and Kenji Kawaguchi  \\
<span style="color:purple">**ICLR**</span> 2023

- <font size="4">Self-Supervised Set Representation Learning for Unsupervised Meta-Learning</font>
[[paper]](https://openreview.net/forum?id=kIAx30hYi_p) \\
Dong Bok Lee\*, **Seanie Lee**\*, Kenji Kawaguchi, Yunji Kim, Jihwan Bang, Jung-Woo Ha and Sung Ju Hwang (\*: equal contribution)  \\
<span style="color:purple">**ICLR**</span> 2023

- <font size="4">Set-based Meta-Interpolation for Few-Task Meta-Learning</font>
[[paper]](https://arxiv.org/abs/2205.09990) \\
 **Seanie Lee\***, Bruno Andreis\*, Kenji Kawaguchi, Juho Lee and Sung Ju Hwang (\*: equal contribution) \\
<span style="color:purple">**NeurIPS**</span> 2022


- <font size="4">On Divergence Measures for Bayesian Pseudocoresets</font>
[[paper]](http://arxiv.org/abs/2210.06205) \\
 Balhae Kim, Jungwon Choi, **Seanie Lee**, Yoonho Lee, Jung-Woo Ha and Juho Lee \\
<span style="color:purple">**NeurIPS**</span> 2022


- <font size="4">Set Based Stochastic Subsampling</font>
[[paper]](https://arxiv.org/abs/2006.14222) \\
Bruno Andreis, **Seanie Lee**, A. Tuan Nguyen, Juho Lee, Eunho Yang and Sung Ju Hwang \\
<span style="color:purple">**ICML**</span> 2022

- <font size="4">Sequential Reptile: Inter-Task Gradient Alignment for Multilingual Learning</font>
[[paper]](https://openreview.net/forum?id=ivQruZvXxtz) \\
**Seanie Lee\***, Hae Beom Lee\*, Juho Lee and Sung Ju Hwang (\*: equal contribution) \\
<span style="color:purple">**ICLR**</span> 2022

- <font size="4">Learning to Perturb Word Embeddings for Out-of-distribution QA</font>
[[paper]](https://aclanthology.org/2021.acl-long.434/) \\
**Seanie Lee\***, Minki Kang\*, Juho Lee and Sung Ju Hwang (\*: equal contribution) \\
<span style="color:purple">**ACL**</span> 2021

- <font size="4">Contrastive Learning with Adversarial Perturbations for Conditional Text Generation</font>
[[paper]](https://openreview.net/forum?id=Wga_hrCa3P3) \\
**Seanie Lee\***, Dong Bok Lee\* and Sung Ju Hwang (\*: equal contribution) \\
<span style="color:purple">**ICLR**</span> 2021


- <font size="4">Meta-GMVAE: Mixture of Gaussian VAE for Unsupervised Meta-Learning</font>
[[paper]](https://openreview.net/forum?id=wS0UFjsNYjn) \\
Dong Bok Lee, Dongchan Min, **Seanie Lee** and Sung Ju Hwang \\
<span style="color:purple">**ICLR**</span> 2021


- <font size="4">Generating Diverse and Consistent QA pairs from Contexts with Information-Maximizing Hierarchical Conditional VAEs</font>
[[paper]](https://aclanthology.org/2020.acl-main.20/) \\
 Dong Bok Lee\*, **Seanie Lee\***, WooTae Jeong, Donghwan Kim and Sung Ju Hwang (\*: equal contribution) \\
<span style="color:purple">**ACL**</span> 2020


- <font size="4">g2pM: A Neural Grapheme-to-Phoneme Conversion Package for Mandarin Chinese Based on a New Open Benchmark Dataset</font>
[[paper]](https://www.isca-speech.org/archive/pdfs/interspeech_2020/park20c_interspeech.pdf) \\
Kyubyong Park\* and **Seanie Lee\*** (\*: equal contribution) \\
<span style="color:purple">**INTERSPEECH**</span> 2020



# üéñ Honors and Awards
- *2023.03* A 2023 recipient of the <a href="https://machinelearning.apple.com/updates/apple-scholars-aiml-2023" style="color: #7289da; text-decoration: none;">Apple Scholars in AI ML PhD fellowship</a>.
- **Google Travel Grant** for NeurIPS 2022 from Google
- *2018.12* <a href="https://github.com/naver/nlp-challenge" style="color: #7289da; text-decoration: none;">Silver Medal in NLP challenge</a>.
<!-- - *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  -->

# üìñ Educations
- *2022.03 - present*, PhD. in Artificial Intelligence. Korea Advanced Institute of Science and Technology.
- *2020.03 - 2022.02*, M.S. in Artificial Intelligence. Korea Advanced Institute of Science and Technology.
- *2011.03 - 2018.02*, B.A. in Library and Information Science. Yonsei University.
<!-- - *2008.03 - 2011.02*, Hanyoung Foreign Language High School. -->


# üíª Internships
- *2024.01* - *2024.06*, Internship at <a href="https://mila.quebec/en/" style="color: #7289da; text-decoration: none;">Mila</a>. Host: <a href="https://yoshuabengio.org/" style="color: #7289da; text-decoration: none;">Yoshua Bengio</a>.

- *2023.06*- *2023.09*, Internship at Apple Cambridge. Host: <a href="http://www.johannsen.com/" style="color: #7289da; text-decoration: none;">Anders Johannsen</a>.
- *2022.06* - *2022.09*, Remote internship at <a href="https://ml.comp.nus.edu.sg/" style="color: #7289da; text-decoration: none;">NUS</a>. Host: <a href="https://ml.comp.nus.edu.sg/kawaguchi" style="color: #7289da; text-decoration: none;">Kenji Kawaguchi</a>.


# üí¨ Invited Talks
- *2023.10*, Tech. Talk, <a href="https://www.th-nuernberg.de/en/" style="color: #7289da; text-decoration: none;">Technische Hochschule N√ºrnberg Georg Simon Ohm</a>. Present <a href="https://docs.google.com/presentation/d/1s0M7g0kkl2tfiAEiX51uMoaAY7-EuEXt/edit?usp=sharing&ouid=117903268632818009810&rtpof=true&sd=true" style="color: #7289da; text-decoration: none;">Scalable Set Encoding with Universal Mini-Batch Consistency and Unbiased Full Set Gradient Approximation</a>.
- *2023.05*, Tech. Talk, Samsung SDS. Present <a href="https://docs.google.com/presentation/d/1s0M7g0kkl2tfiAEiX51uMoaAY7-EuEXt/edit?usp=sharing&ouid=117903268632818009810&rtpof=true&sd=true" style="color: #7289da; text-decoration: none;">Scalable Set Encoding with Universal Mini-Batch Consistency and Unbiased Full Set Gradient Approximation</a>.
- *2021.12*, Tech. Talk, NAVER corp. Present ACL 2020 paper. 
<!-- - *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/) -->
